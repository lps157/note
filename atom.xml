<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://github.com/lps157</id>
    <title>lps&apos; note</title>
    <updated>2020-01-03T07:48:00.970Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://github.com/lps157"/>
    <link rel="self" href="https://github.com/lps157/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://github.com/lps157/images/avatar.png</logo>
    <icon>https://github.com/lps157/favicon.ico</icon>
    <rights>All rights reserved 2020, lps&apos; note</rights>
    <entry>
        <title type="html"><![CDATA[Spark RDD、DataFrame、DataSet的区别和联系以及优缺点]]></title>
        <id>https://github.com/lps157/post/spark-rdddataframedataset-de-qu-bie-he-lian-xi-yi-ji-you-que-dian</id>
        <link href="https://github.com/lps157/post/spark-rdddataframedataset-de-qu-bie-he-lian-xi-yi-ji-you-que-dian">
        </link>
        <updated>2019-12-31T06:39:12.000Z</updated>
        <summary type="html"><![CDATA[<p>1.1 DataFrame概念<br>
什么是DataFrame<br>
DataFrame的前身是SchemaRDD，从Spark 1.3.0开始SchemaRDD更名为DataFrame。并不再直接继承自RDD，而是自己实现了RDD的绝大多数功能。<br>
DataFrame是一种以RDD为基础的分布式数据集，类似于传统数据库的二维表格，带有Schema元信息(可以理解为数据库的列名和类型)</p>
<p>●总结:</p>
]]></summary>
        <content type="html"><![CDATA[<p>1.1 DataFrame概念<br>
什么是DataFrame<br>
DataFrame的前身是SchemaRDD，从Spark 1.3.0开始SchemaRDD更名为DataFrame。并不再直接继承自RDD，而是自己实现了RDD的绝大多数功能。<br>
DataFrame是一种以RDD为基础的分布式数据集，类似于传统数据库的二维表格，带有Schema元信息(可以理解为数据库的列名和类型)</p>
<p>●总结:</p>
<!-- more -->
<p>DataFrame就是一个分布式的表<br>
DataFrame = RDD - 泛型  + SQL的操作 + 优化</p>
<p>1.2  DataSet概念<br>
什么是DataSet<br>
DataSet是在Spark1.6中添加的新的接口。<br>
与RDD相比，保存了更多的描述信息，概念上等同于关系型数据库中的二维表。<br>
与DataFrame相比，保存了类型信息，是强类型的，提供了编译时类型检查，<br>
调用Dataset的方法先会生成逻辑计划，然后被spark的优化器进行优化，最终生成物理计划，然后提交到集群中运行！</p>
<p>DataSet包含了DataFrame的功能，<br>
Spark2.0中两者统一，DataFrame表示为DataSet[Row]，即DataSet的子集。<br>
DataFrame其实就是Dateset[Row]<br>
<img src="https://raw.githubusercontent.com/lps157/note/master/img/20191231151404.jpg" alt="" loading="lazy"><br>
●总结:<br>
Dateset ==&gt; DataFrame + 泛型<br>
Dateset ==&gt; RDD + Schema + 方便的SQL操作 + 优化<br>
Dateset是特殊的DataFrame、DataFrame是特殊的RDD<br>
Dateset是一个分布式的表</p>
<p>1.3.1 RDD、DataFrame、DataSet的区别<br>
●结构图解<br>
<img src="https://raw.githubusercontent.com/lps157/note/master/img/20191231152409.jpeg" alt="" loading="lazy"></p>
<p>RDD[Person]<br>
以Person为类型参数，但不了解 其内部结构。<br>
DataFrame<br>
提供了详细的结构信息schema列的名称和类型。这样看起来就像一张表了<br>
DataSet[Person]<br>
不光有schema信息，还有类型信息</p>
<p>●数据图解<br>
1.假设RDD中的两行数据长这样：<br>
RDD[Person]<br>
<img src="https://raw.githubusercontent.com/lps157/note/master/img/20191231152451.png" alt="" loading="lazy"></p>
<p>2.那么DataFrame中的数据长这样<br>
DataFrame = RDD[Person] - 泛型 + Schema + SQL操作 + 优化<br>
<img src="https://raw.githubusercontent.com/lps157/note/master/img/20191231152534.png" alt="" loading="lazy"></p>
<p>3.那么Dataset中的数据长这样:<br>
Dataset[Person] = DataFrame + 泛型<br>
<img src="https://raw.githubusercontent.com/lps157/note/master/img/20191231152557.png" alt="" loading="lazy"></p>
<p>4.Dataset也可能长这样:Dataset[Row]DataFrame = DataSet[Row]<br>
<img src="https://raw.githubusercontent.com/lps157/note/master/img/20191231152752.png" alt="" loading="lazy"></p>
<p>1.3.2  总结<br>
DataFrame = RDD - 泛型  +  Schema  + SQL + 优化<br>
DataSet = DataFrame  + 泛型<br>
DataSet  =  RDD   +  Schema  + SQL + 优化</p>
<p>2.1 各自的优点和缺点</p>
<ol>
<li>RDD<br>
优点:<br>
编译时类型安全<br>
编译时就能检查出类型错误<br>
面向对象的编程风格<br>
直接通过类名点的方式来操作数据<br>
缺点:<br>
序列化和反序列化的性能开销<br>
无论是集群间的通信, 还是IO操作都需要对对象的结构和数据进行序列化和反序列化。<br>
GC的性能开销，频繁的创建和销毁对象, 势必会增加GC</li>
<li>DataFrame<br>
优点:<br>
DataFrame引入了schema和off-heap<br>
schema : RDD每一行的数据, 结构都是一样的，这个结构就存储在schema中。 Spark通过schema就能够读懂数据, 因此在通信和IO时就只需要序列化和反序列化数据, 而结构的部分就可以省略了。<br>
off-heap：操作数据时直接操作off-heap中的数据，可以快速地操作数据，避免了大量gc<br>
缺点:<br>
不是类型安全的<br>
API也不是面向对象风格的</li>
<li>DataSet<br>
优点：<br>
DataSet结合了RDD和DataFrame的优点，并带来的一个新的概念Encoder。<br>
当序列化数据时，Encoder产生字节码与off-heap进行交互，能够达到按需访问数据的效果，而不用反序列化整个对象。Spark还没有提供自定义Encoder的API，但是未来会加入。</li>
</ol>
<p>2.2 三者之间的转换：<br>
<img src="https://raw.githubusercontent.com/lps157/note/master/img/20191231152957.jpeg" alt="" loading="lazy"></p>
<!-- more -->
]]></content>
    </entry>
</feed>